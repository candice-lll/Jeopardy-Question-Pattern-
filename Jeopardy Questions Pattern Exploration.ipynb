{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning Jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I am going to explore Jeopardy data to see if any  pattern in the questiones.\n",
    "\n",
    "The dataset is named jeopardy.csv and contains 20000 rows from the beginning of a full dataset of Jeopardy questions.\n",
    "\n",
    "Each row in the dataset represents a single question on a single episode of Jeopardy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv('jeopardy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      "Show Number    19999 non-null int64\n",
      " Air Date      19999 non-null object\n",
      " Round         19999 non-null object\n",
      " Category      19999 non-null object\n",
      " Value         19999 non-null object\n",
      " Question      19999 non-null object\n",
      " Answer        19999 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creat a function to remove the spaces in each item in jeopardy.columns.\n",
    "df.columns=df.columns.str.strip()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to normalize all of the text columns (the Question and Answer columns).We need to ensure that you lowercase words and remove punctuation so Don't and don't aren't considered to be different words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize(string):\n",
    "    text=string.lower()\n",
    "    text=re.sub('[^\\w\\s]','',text)\n",
    "    return text\n",
    "\n",
    "df['clean_question']=df['Question'].apply(normalize)\n",
    "df['clean_answer']=df['Answer'].apply(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Value column should also be numeric, to allow you to manipulate it more easily. We need to remove the dollar sign from the beginning of each value and convert the column from text to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_value(string):\n",
    "    value=re.sub('[^\\w\\s]','',string)\n",
    "    try:\n",
    "        value=int(value)\n",
    "    except Exception:\n",
    "        value=0\n",
    "    return value\n",
    "\n",
    "normalize_value('$200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['clean_value']=df['Value'].apply(normalize_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Air Date data type from object to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 10 columns):\n",
      "Show Number       19999 non-null int64\n",
      "Air Date          19999 non-null datetime64[ns]\n",
      "Round             19999 non-null object\n",
      "Category          19999 non-null object\n",
      "Value             19999 non-null object\n",
      "Question          19999 non-null object\n",
      "Answer            19999 non-null object\n",
      "clean_question    19999 non-null object\n",
      "clean_answer      19999 non-null object\n",
      "clean_value       19999 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(2), object(7)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df['Air Date']=pd.to_datetime(df['Air Date'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analysis\n",
    "In order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "1,How often the answer is deducible from the question.\n",
    "2,How often new questions are repeats of older questions.\n",
    "We can answer the second question by seeing how often complex words (> 6 characters) reoccur. We can answer the first question by seeing how many times words in the answer also occur in the question. We'll work on the first question now, and come back to the second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1,How often the answer is deducible from the question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05900196524977763"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_matches_ratio(row):\n",
    "    answer = row['clean_answer']\n",
    "    question = row['clean_question']\n",
    "    split_answer = answer.split()\n",
    "    split_question = question.split()\n",
    "    match_count = 0\n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1\n",
    "    return match_count/len(split_answer)\n",
    "  \n",
    "df['answer_in_question'] = df.apply(count_matches_ratio, axis = 1)  \n",
    "df['answer_in_question'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 6% of words are found in the questions. It is a quiet low number. We can't deduce answer from the question.  Hence,We have to study the question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2,How often new questions are repeats of older questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6894006357823182"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "df.sort_values('Air Date', inplace = True)\n",
    "for i, row in df.iterrows():\n",
    "    split_question = row['clean_question'].split()\n",
    "    split_question = [q for q in split_question if len(q)>= 6]\n",
    "    match_count = 0\n",
    "    for term in split_question:\n",
    "        if term in terms_used:\n",
    "            match_count += 1\n",
    "        else:\n",
    "            terms_used.add(term)\n",
    "    if len(split_question) > 0:\n",
    "        match_count = match_count / len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "    \n",
    "df['question_overlap']=question_overlap\n",
    "df['question_overlap'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "69% of question overlap means that 69% of words in new questions are same as old question. It is not low number, however, we are studying on single words only instaed of a phrase, which means that it is relatively insignificant, but it does mean that it's worth looking more into the recycling of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low value vs high value questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If we want to study only high value questions to win more money. We can figure out which terms correspond to high-value questions using a chi-squared test.\n",
    "\n",
    "We'll first need to narrow down the questions into two categories:\n",
    "\n",
    "Low value -- Any row where Value is less than 800.\n",
    "High value -- Any row where Value is greater than 800.\n",
    "\n",
    "We'll then be able to loop through each of the terms from the last screen, terms_used, and:\n",
    "\n",
    "-Find the number of low value questions the word occurs in.\n",
    "-Find the number of high value questions the word occurs in.\n",
    "-Find the percentage of questions the word occurs in.\n",
    "-Based on the percentage of questions the word occurs in, find expected counts.\n",
    "-Compute the chi squared value based on the expected counts and the observed counts for high and low value questions.\n",
    "\n",
    "We can then find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values. Doing this for all of the words would take a very long time, so we'll just do it for a small sample now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28671433571678584"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def determin_value(row):\n",
    "        if row['clean_value']>800:\n",
    "            value=1\n",
    "        else:\n",
    "            value=0\n",
    "        return value\n",
    "\n",
    "df['high_value'] = df.apply(determin_value, axis = 1)    \n",
    "df['high_value'].sum()/len(df['high_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 29% questions are categoried as high-value question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_word(word):\n",
    "    low_count=0\n",
    "    high_count=0\n",
    "    for i,row in df.iterrows():\n",
    "        spli_ques=row['clean_question'].split()\n",
    "        if word in spli_ques:\n",
    "            if row['high_value']==1:\n",
    "                high_count +=1\n",
    "            else:\n",
    "                low_count +=1\n",
    "    return low_count,high_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['immense',\n",
       " 'livres',\n",
       " 'unauthorized',\n",
       " 'dagger',\n",
       " 'selling',\n",
       " 'topten',\n",
       " 'undefeated',\n",
       " 'chalabi',\n",
       " 'leprosy',\n",
       " 'christendom']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_used_list=list(terms_used)\n",
    "import random \n",
    "sample=random.sample(terms_used_list,10)\n",
    "comparison_terms=sample\n",
    "comparison_terms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['immense', 'livres', 'unauthorized', 'dagger', 'selling', 'topten', 'undefeated', 'chalabi', 'leprosy', 'christendom']\n",
      "[(2, 0), (1, 0), (1, 0), (1, 0), (14, 3), (1, 0), (2, 0), (1, 0), (1, 0), (1, 0)]\n"
     ]
    }
   ],
   "source": [
    "observed_expected=[]\n",
    "for word in comparison_terms:\n",
    "    observed_expected.append(count_word(word))\n",
    "\n",
    "    \n",
    "print(comparison_terms)    \n",
    "print(observed_expected)#use observed counts to compute expercted counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Squared Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've found the observed counts for a few terms, you can compute the expected counts and the chi-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=22.21568659171183, pvalue=2.436747872923759e-06),\n",
       " Power_divergenceResult(statistic=11.268291701322743, pvalue=0.0007884224991512313),\n",
       " Power_divergenceResult(statistic=33.2332216282488, pvalue=8.17420115468397e-09),\n",
       " Power_divergenceResult(statistic=11.268291701322743, pvalue=0.0007884224991512313),\n",
       " Power_divergenceResult(statistic=44.63061715194016, pvalue=2.3794153105180522e-11),\n",
       " Power_divergenceResult(statistic=11.107843295855915, pvalue=0.0008596339784277207),\n",
       " Power_divergenceResult(statistic=377.36865867552007, pvalue=4.654261402112294e-84),\n",
       " Power_divergenceResult(statistic=11.268291701322743, pvalue=0.0007884224991512313),\n",
       " Power_divergenceResult(statistic=11.268291701322743, pvalue=0.0007884224991512313),\n",
       " Power_divergenceResult(statistic=11.107843295855915, pvalue=0.0008596339784277207)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "high_value_count = df[df[\"high_value\"] == 1].shape[0]\n",
    "low_value_count = df[df[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n",
    "for obs in observed_expected:\n",
    "    total = sum(obs)\n",
    "    total_prop = total / df.shape[0]\n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([obs[0], obs[1]])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Chi-squared results\n",
    "None of the terms had a significant difference in usage between high value and low value rows. Additionally, the frequencies were all lower than 5, so the chi-squared test isn't as valid. It would be better to run this test with only terms that have higher frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "-On average about 6% of the words of answers are found in the questions. So the chance of deducing the answer from the question is quite low.\n",
    "-About 69% of the complex words in questions are repeated so studying the past questions can be really helpful to win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
